{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Use Head2Toe and transfer learning "
      ],
      "metadata": {
        "id": "Sn0ooqh0vNBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model FineTuning loop"
      ],
      "metadata": {
        "id": "DD-huGGgvZ1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import copy\n",
        "import math\n",
        "from absl import logging\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_hub as hub\n",
        "# nohidden: just output layer.\n",
        "# random_100: 1 non-trainable hidden layer with 100 units.\n",
        "# random_1000: ... with 1000 units.\n",
        "# trainable_100: 1 trainable hidden layer with 100 units.\n",
        "# trainable_1000: ... with 1000 units.\n",
        "OUTPUT_HEAD_TYPES = ['nohidden', 'random', 'trainable']\n",
        "\n",
        "\n",
        "def zero_aware_normalize(embedding, axis):\n",
        "  \"\"\"If the norm is zero leaves the row unnormalized.\"\"\"\n",
        "  # Following will have nans when the norm of vector(the divider) is zero.\n",
        "  normalized, norms = tf.linalg.normalize(embedding, axis=axis)\n",
        "  is_zero_norm = tf.broadcast_to(tf.equal(norms, 0), normalized.shape)\n",
        "  return tf.where(is_zero_norm, tf.zeros_like(embedding), normalized)\n",
        "\n",
        "\n",
        "def _check_and_convert(norm_ord):\n",
        "  \"\"\"Validates the order is positive or 'inf'.\"\"\"\n",
        "  if isinstance(norm_ord, (float, int)) and norm_ord > 0:\n",
        "    return norm_ord\n",
        "  elif isinstance(norm_ord, str) and norm_ord == 'inf':\n",
        "    return np.inf\n",
        "  else:\n",
        "    raise ValueError(f'norm_order:{norm_ord} is not valid')\n",
        "\n",
        "\n",
        "class GroupLRP(tf.keras.regularizers.Regularizer):\n",
        "  \"\"\"A regularizer that applies Group L-r/p penalty to the weights.\n",
        "  The L-r/p regularization penalty is computed as:\n",
        "  `loss = coef * norm(norm(x, ord=r, axis=1), ord=p)`\n",
        "  Attributes:\n",
        "      coef: Float; regularization factor.\n",
        "      r: int, Must be >0. or 'inf'\n",
        "      p: int, Must be >0. or 'inf'\n",
        "      group_sizes: iterable or None; used to split feature vector into tensors.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, coef=0., r=2, p=1, group_sizes=None):\n",
        "    self.coef = tf.keras.backend.cast_to_floatx(coef)\n",
        "    self.r = _check_and_convert(r)\n",
        "    self.p = _check_and_convert(p)\n",
        "    self.group_sizes = group_sizes\n",
        "\n",
        "  def __call__(self, x):\n",
        "    regularization = tf.keras.backend.constant(0., dtype=x.dtype)\n",
        "    if self.coef:\n",
        "      if self.group_sizes:\n",
        "        group_norms = []\n",
        "        for group in tf.split(x, self.group_sizes, axis=0):\n",
        "          group_norms.append(tf.norm(tf.reshape(group, [-1]), ord=self.r))\n",
        "        regularization += tf.norm(tf.stack(group_norms), ord=self.p)\n",
        "      else:\n",
        "        regularization += self.coef * tf.norm(\n",
        "            tf.norm(x, axis=1, ord=self.r), ord=self.p)\n",
        "    return regularization\n",
        "\n",
        "  def get_config(self):\n",
        "    return {'coef': float(self.coef), 'r': self.r, 'p': self.p,\n",
        "            'group_sizes': tuple(self.group_sizes)}\n",
        "\n",
        "\n",
        "class Finetune(tf.keras.Model):\n",
        "  \"\"\"A `tf.keras.Model` implementation of Finetune.\n",
        "  This learner trains a linear classifier on top of the features given.\n",
        "  TODO Split finetune_backbone implementation from linear probe.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, config):\n",
        "    \"\"\"Initializes a `Finetune` instance.\n",
        "    Args:\n",
        "      config: a `ConfigDict` specifying the backbones configuration.\n",
        "    \"\"\"\n",
        "    super(Finetune, self).__init__()\n",
        "    self._backbone_config = config.backbone\n",
        "    self._learning_config = config.learning\n",
        "    available_gpus = tf.config.list_physical_devices(device_type='GPU')\n",
        "    if config.max_num_gpus > len(available_gpus):\n",
        "      logging.warning('config.max_num_gpus: %s > n_gpus', config.max_num_gpus)\n",
        "    else:\n",
        "      available_gpus = available_gpus[:config.max_num_gpus]\n",
        "    logging.info('N_GPUS: %d in use', len(available_gpus))\n",
        "    # To get /physical_device:GPU:0\n",
        "    available_gpus = [':'.join(g.name.split(':')[1:]) for g in available_gpus]\n",
        "    self.strategy = tf.distribute.MirroredStrategy(devices=available_gpus)\n",
        "    with self.strategy.scope():\n",
        "      res = self.load_backbones()\n",
        "      self.backbones, self.backbone_names, self.embedding_sizes = res\n",
        "\n",
        "  def load_backbones(self):\n",
        "    backbone_config = self._backbone_config\n",
        "    # Load pre-trained backbones.\n",
        "    backbones = []\n",
        "    backbone_names = []\n",
        "    embedding_sizes = []\n",
        "    for name, handle, signature, output_key, size in zip(\n",
        "        backbone_config.names,\n",
        "        backbone_config.handles,\n",
        "        backbone_config.signatures,\n",
        "        backbone_config.output_keys,\n",
        "        backbone_config.input_sizes):\n",
        "\n",
        "      if self._learning_config.finetune_backbones:\n",
        "        backbone = hub.KerasLayer(handle, trainable=True)\n",
        "      elif signature is None:\n",
        "        backbone = hub.KerasLayer(handle, trainable=False)\n",
        "      else:\n",
        "        backbone = hub.KerasLayer(\n",
        "            handle, signature=signature, output_key=None,\n",
        "            trainable=False, signature_outputs_as_dict=True)\n",
        "      inputs = tf.keras.Input(shape=(None, None, 3))\n",
        "      resized_inputs = inputs\n",
        "      if size is not None:\n",
        "        inputs = tf.keras.Input(shape=(size, size, 3))\n",
        "        resized_inputs = tf.image.resize(inputs, size=[size, size])\n",
        "      outputs = backbone(resized_inputs)\n",
        "      if backbone_config.additional_features:\n",
        "        updated_outputs = []\n",
        "        all_output_keys = [output_key]\n",
        "        if backbone_config.include_input:\n",
        "          outputs['input'] = resized_inputs\n",
        "          all_output_keys.append('input')\n",
        "        all_output_keys.extend(\n",
        "            backbone_config.additional_features.strip().split(','))\n",
        "        if backbone_config.additional_features_multi_target_sizes:\n",
        "          t_sizes = backbone_config.additional_features_multi_target_sizes\n",
        "          target_embedding_sizes = t_sizes.strip().split(',')\n",
        "        else:\n",
        "          target_embedding_sizes = [\n",
        "              backbone_config.additional_features_target_size]\n",
        "        # TODO Probably use the function to get multiple pooled features.\n",
        "        # It should also return the names maybe.\n",
        "        # Also it might be more straight forward to use pool_sizes.\n",
        "        for target_embedding_size in target_embedding_sizes:\n",
        "          new_outputs = flatten_and_concat(\n",
        "              outputs, output_keys=all_output_keys,\n",
        "              pool_size=backbone_config.additional_features_pool_size,\n",
        "              target_size=int(target_embedding_size),\n",
        "              cls_token_pool=backbone_config.cls_token_pool)\n",
        "          new_names = [f'{name}_{n}_{target_embedding_size}' for n\n",
        "                       in all_output_keys]\n",
        "          for newname, out in zip(new_names, new_outputs):\n",
        "            logging.info('Backbone name: %s, shape: %s', newname, out.shape)\n",
        "            backbone_names.append(newname)\n",
        "            embedding_sizes.append(out.shape[-1])\n",
        "          updated_outputs += new_outputs\n",
        "        outputs = updated_outputs\n",
        "      else:\n",
        "        outputs = outputs[output_key]\n",
        "        logging.info('Backbone name: %s, shape: %s', name, outputs.shape)\n",
        "        backbone_names.append(name)\n",
        "        embedding_sizes.append(outputs.shape[-1])\n",
        "      backbone = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "      backbones.append(backbone)\n",
        "    return backbones, backbone_names, embedding_sizes\n",
        "\n",
        "  def _get_optimizer(self, learning_config, n_classes):\n",
        "    learning_rate = learning_config.learning_rate\n",
        "    clipvalue = (learning_config.grad_clip_value\n",
        "                 if learning_config.grad_clip_value > 0 else None)\n",
        "    if learning_config.use_cosine_decay:\n",
        "      learning_rate = tf.keras.experimental.CosineDecay(\n",
        "          learning_rate, learning_config.training_steps)\n",
        "    optimizer = learning_config.optimizer\n",
        "    if optimizer == 'adam':\n",
        "      optimizer = tf.optimizers.Adam(learning_rate, clipvalue=clipvalue)\n",
        "    elif optimizer == 'sgd':\n",
        "      optimizer = tf.optimizers.SGD(learning_rate, momentum=0.9,\n",
        "                                    clipvalue=clipvalue)\n",
        "    else:\n",
        "      raise ValueError('Unknown optimizer')\n",
        "    return optimizer\n",
        "\n",
        "  def _embed_batch(self, x, is_training=False):\n",
        "    \"\"\"Compute the feature representation of a batch.\n",
        "    Args:\n",
        "      x: input tensor.\n",
        "      is_training: bool, passed to the backbone.\n",
        "    Returns:\n",
        "      embedding_list: A list of tf.Tensors.\n",
        "    \"\"\"\n",
        "    embedding_list = []\n",
        "    for backbone in self.backbones:\n",
        "      output_backbone = backbone(x, training=is_training)\n",
        "      # Note that the output of the backbone can be a list.\n",
        "      if isinstance(output_backbone, list):\n",
        "        for out in output_backbone:\n",
        "          embedding_list.append(out)\n",
        "      else:\n",
        "        embedding_list.append(output_backbone)\n",
        "    return embedding_list\n",
        "\n",
        "  def _embed_dataset(self, dataset):\n",
        "    \"\"\"Compute the feature representation of a batch.\n",
        "    Args:\n",
        "      dataset: a `tf.data.Dataset` corresponding to the support or query set.\n",
        "    Returns:\n",
        "      embeddings: A list of tf.Tensors.\n",
        "      labels: A tf.Tensor.\n",
        "    \"\"\"\n",
        "    batch_embedding_lists = []\n",
        "    labels = []\n",
        "    for x, y in dataset:\n",
        "      labels.append(y)\n",
        "      batch_embedding_lists.append(self._embed_batch(x))\n",
        "\n",
        "    labels = tf.concat(labels, axis=0)\n",
        "    output_embeddings = []\n",
        "    for i in range(len(batch_embedding_lists[0])):\n",
        "      embedding_i = [batch[i] for batch in batch_embedding_lists]\n",
        "      output_embeddings.append(tf.concat(embedding_i, axis=0))\n",
        "    return output_embeddings, labels\n",
        "\n",
        "  def _process_metrics(self, metrics):\n",
        "    (support_loss_iter, support_accuracy_iter, query_loss_iter,\n",
        "     query_accuracy_iter) = metrics\n",
        "\n",
        "    ret_dict = {\n",
        "        'support_loss': support_loss_iter[-1],\n",
        "        'support_accuracy': support_accuracy_iter[-1],\n",
        "        'query_loss': query_loss_iter[-1],\n",
        "        'query_accuracy': query_accuracy_iter[-1]\n",
        "                }\n",
        "\n",
        "    return ret_dict\n",
        "\n",
        "  def _process_embeddings(self, embeddings, selected_features,\n",
        "                          normalization='unit_vector'):\n",
        "    \"\"\"Processes embeddings by normalizing an concatenating.\n",
        "    Args:\n",
        "      embeddings: list of Tensors, where each Tensor is the embeddings\n",
        "        of a particular backbone.\n",
        "      selected_features: list of Tensors, where each Tensor indicates the\n",
        "        indices to be selected.\n",
        "      normalization: str, 'unit_vector', 'per_feature_std'.\n",
        "        'unit_vector' SUR style normalization\n",
        "        'per_feature' similar to Batch-Normalization\n",
        "    Returns:\n",
        "      flattened and possibly scaled embeddings.\n",
        "    \"\"\"\n",
        "    # shape= (n_image, n_features)\n",
        "    assert normalization in ('unit_vector', 'per_feature', '')\n",
        "    if selected_features:\n",
        "      # Following removes the backbones altogether if no feature is selected.\n",
        "      embeddings = [\n",
        "          tf.gather(embedding, indices, axis=1) for embedding, indices\n",
        "          in zip(embeddings, selected_features)\n",
        "          if np.prod(indices.shape) > 0\n",
        "      ]\n",
        "    if normalization == 'unit_vector':\n",
        "      embeddings = [zero_aware_normalize(e, axis=1) for e in embeddings]\n",
        "    embeddings = tf.concat(embeddings, -1)\n",
        "    if normalization == 'per_feature':\n",
        "      # Normalize each feature to have unit variance and zero mean.\n",
        "      mean, var = tf.nn.moments(embeddings, axes=0)\n",
        "      bn_args = {'offset': None,\n",
        "                 'scale': None,\n",
        "                 'variance_epsilon': 1e-5}\n",
        "      embeddings = tf.nn.batch_normalization(\n",
        "          embeddings, mean, var, **bn_args)\n",
        "    return embeddings\n",
        "\n",
        "  @tf.function(reduce_retracing=True)\n",
        "  def _compute_loss_and_accuracy(self, output_head, logits, labels,\n",
        "                                 global_batch_size=None):\n",
        "    \"\"\"Computes the loss and accuracy on an episode.\"\"\"\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        labels=labels, logits=logits)\n",
        "    if output_head.losses:\n",
        "      loss += tf.add_n(output_head.losses)\n",
        "    accuracy = tf.cast(tf.equal(\n",
        "        tf.math.argmax(logits, axis=1, output_type=labels.dtype),\n",
        "        labels), tf.float32)\n",
        "    loss = tf.nn.compute_average_loss(loss, global_batch_size=global_batch_size)\n",
        "    accuracy = tf.nn.compute_average_loss(accuracy,\n",
        "                                          global_batch_size=global_batch_size)\n",
        "    return loss, accuracy\n",
        "\n",
        "  def _init_training_vars(self, num_ways, learning_config):\n",
        "    if learning_config.l1_regularizer or learning_config.l2_regularizer:\n",
        "      regularizer = tf.keras.regularizers.L1L2(\n",
        "          l1=learning_config.l1_regularizer, l2=learning_config.l2_regularizer)\n",
        "    elif learning_config.group_lrp_regularizer_coef:\n",
        "      group_sizes = (self.embedding_sizes\n",
        "                     if learning_config.group_lrp_is_embedding else None)\n",
        "      regularizer = GroupLRP(\n",
        "          coef=learning_config.group_lrp_regularizer_coef,\n",
        "          group_sizes=group_sizes,\n",
        "          r=learning_config.group_lrp_regularizer_r,\n",
        "          p=learning_config.group_lrp_regularizer_p)\n",
        "    else:\n",
        "      regularizer = None\n",
        "    output_layers = []\n",
        "    assert any(learning_config.output_head_type.startswith(t)\n",
        "               for t in OUTPUT_HEAD_TYPES)\n",
        "    if learning_config.output_head_type.startswith('random'):\n",
        "      n_units = int(learning_config.output_head_type.split('_')[1])\n",
        "      n_units = n_units if n_units > 0 else num_ways\n",
        "      output_layers.append((n_units, False, 'relu'))\n",
        "    elif learning_config.output_head_type.startswith('trainable'):\n",
        "      n_units = int(learning_config.output_head_type.split('_')[1])\n",
        "      n_units = n_units if n_units > 0 else num_ways\n",
        "      output_layers.append((n_units, True, 'relu'))\n",
        "    # Final layer, this is the only layer when type=nohidden.\n",
        "    output_layers.append((num_ways, True, None))\n",
        "    output_head = tf.keras.Sequential()\n",
        "    for i, (n_features, is_trainable, f_activation) in enumerate(output_layers):\n",
        "      kwargs_dense = {'trainable': is_trainable}\n",
        "      if i == 0 and learning_config.output_head_zeroinit:\n",
        "        logging.info('First layer in output head is zero initialized.')\n",
        "        kwargs_dense['kernel_initializer'] = tf.zeros\n",
        "      new_layer = tf.keras.layers.Dense(\n",
        "          n_features, activation=f_activation, kernel_regularizer=regularizer,\n",
        "          **kwargs_dense)\n",
        "      output_head.add(new_layer)\n",
        "    return output_head\n",
        "\n",
        "  def evaluate(self, learning_config, support_dataset, query_dataset,\n",
        "               **unused_kwargs):\n",
        "    \"\"\"Performs evaluation on an episode.\n",
        "    Args:\n",
        "      learning_config: a `ConfigDict` specifying the learning configuration.\n",
        "      support_dataset: a `tf.data.Dataset` for the support set.\n",
        "      query_dataset: a `tf.data.Dataset` for the query set.\n",
        "    Returns:\n",
        "      metrics: dict mapping metric names to metrics.\n",
        "    \"\"\"\n",
        "    metrics = self._optimize_finetune(\n",
        "        learning_config, support_dataset, query_dataset)\n",
        "    return_dict = self._process_metrics(metrics)\n",
        "    return return_dict\n",
        "\n",
        "  def _optimize_finetune(self, learning_config, support_dataset, query_dataset,\n",
        "                         selected_feature_indices=None,\n",
        "                         return_output_head=False):\n",
        "    \"\"\"Optimize the output layers and possibly the backbones, too.\n",
        "    Args:\n",
        "      learning_config: A ConfigDict.\n",
        "      support_dataset: a `tf.data.Dataset` for the support set.\n",
        "      query_dataset: a `tf.data.Dataset` or None for the query set.\n",
        "      selected_feature_indices: defines which features are selected.\n",
        "      return_output_head: bool that decides what is returned. If true, this\n",
        "        means we return the trained output head and also don't calculate query\n",
        "        performance.\n",
        "    Returns:\n",
        "      lambda_logits: The optimized lambdas or None.\n",
        "      support_loss_iter: A list of iterate values.\n",
        "      support_accuracy_iter: A list of iterate values.\n",
        "      query_loss_iter: A list of iterate values.\n",
        "      query_accuracy_iter: A list of iterate values.\n",
        "    \"\"\"\n",
        "    if selected_feature_indices:\n",
        "      # Print statistics\n",
        "      for name, indices in zip(self.backbone_names, selected_feature_indices):\n",
        "        logging.info('Backbone: %s, selected %d', name, len(indices))\n",
        "    # Pre-generate the embeddings\n",
        "    with tf.device('/CPU:0'):\n",
        "      support_embeddings, support_labels = self._embed_dataset(support_dataset)\n",
        "      # Normalize the data\n",
        "      support_representation = self._process_embeddings(\n",
        "          support_embeddings, selected_feature_indices,\n",
        "          normalization=learning_config.feature_normalization)\n",
        "      logging.info('Support representation shape: %s',\n",
        "                   support_representation.shape)\n",
        "    if query_dataset is None:\n",
        "      query_labels = tf.constant([], dtype=support_labels.dtype)\n",
        "    elif learning_config.cached_eval:\n",
        "      with tf.device('/CPU:0'):\n",
        "        query_embeddings, query_labels = self._embed_dataset(query_dataset)\n",
        "        query_representation = self._process_embeddings(\n",
        "            query_embeddings, selected_feature_indices,\n",
        "            normalization=learning_config.feature_normalization)\n",
        "    else:\n",
        "      # We still need query labels to get number of classes. In some situations\n",
        "      # Support set might not have all classes, and then our output head\n",
        "      # would be smaller, which creates NaNs in loss calculation when\n",
        "      # tf.nn.sparse_softmax_cross_entropy_with_logits is used.\n",
        "      all_labels = []\n",
        "      for _, batch_labels in query_dataset:\n",
        "        all_labels.append(batch_labels)\n",
        "      query_labels = tf.concat(all_labels, axis=0)\n",
        "    support_loss_iter = []\n",
        "    support_accuracy_iter = []\n",
        "    query_loss_iter = []\n",
        "    query_accuracy_iter = []\n",
        "    all_labels = tf.concat([support_labels, query_labels], 0)\n",
        "    num_ways = tf.cast(tf.math.reduce_max(tf.unique(all_labels)[0]) + 1,\n",
        "                       tf.int32)\n",
        "    with self.strategy.scope():\n",
        "      if (learning_config.finetune_backbones and\n",
        "          learning_config.finetune_lr_multiplier != 1.):\n",
        "        learning_config = copy.deepcopy(learning_config)\n",
        "        new_lr = (learning_config['learning_rate'] *\n",
        "                  learning_config.finetune_lr_multiplier)\n",
        "        learning_config['learning_rate'] = new_lr\n",
        "        logging.info('Finetuning learning rate is updated to %s',\n",
        "                     new_lr)\n",
        "      if (learning_config.finetune_backbones and\n",
        "          learning_config.finetune_steps_multiplier != 1.):\n",
        "        learning_config = copy.deepcopy(learning_config)\n",
        "        new_steps = int(learning_config['training_steps'] *\n",
        "                        learning_config.finetune_steps_multiplier)\n",
        "        learning_config['training_steps'] = new_steps\n",
        "        logging.info('Finetuning training steps are updated to %s', new_steps)\n",
        "      optimizer = self._get_optimizer(learning_config, num_ways)\n",
        "      output_head = self._init_training_vars(num_ways, learning_config)\n",
        "      # Initialize the layer\n",
        "      output_head(support_representation[:1])\n",
        "\n",
        "    training_vars = output_head.trainable_variables\n",
        "    if learning_config.finetune_backbones:\n",
        "      for b in self.backbones:\n",
        "        training_vars.extend(b.trainable_variables)\n",
        "    else:\n",
        "      batch_size = learning_config.train_batch_size\n",
        "      # Regenerate the dataset with precomputed embeddings.\n",
        "      support_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "          (support_representation, support_labels)).batch(batch_size)\n",
        "      if query_dataset and learning_config.cached_eval:\n",
        "        query_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "            (query_representation, query_labels)).batch(\n",
        "                learning_config.eval_batch_size)\n",
        "    logging.info('Trainable variables: %s', [v.name for v in training_vars])\n",
        "    support_dataset = support_dataset.repeat()\n",
        "    dist_support_dataset = self.strategy.experimental_distribute_dataset(\n",
        "        support_dataset)\n",
        "    if query_dataset:\n",
        "      dist_query_dataset = self.strategy.experimental_distribute_dataset(\n",
        "          query_dataset)\n",
        "\n",
        "    @tf.function()\n",
        "    def _train_step(x, y):\n",
        "      with tf.GradientTape() as tape:\n",
        "        if learning_config.finetune_backbones:\n",
        "          # Pass the images through multiple backbones.\n",
        "          embeddings = self._embed_batch(x, is_training=True)\n",
        "          # Normalize the data\n",
        "          x = self._process_embeddings(\n",
        "              embeddings, selected_feature_indices,\n",
        "              normalization=learning_config.feature_normalization)\n",
        "        logits = output_head(x)\n",
        "        loss, accuracy = self._compute_loss_and_accuracy(\n",
        "            output_head, logits, y,\n",
        "            global_batch_size=learning_config.train_batch_size)\n",
        "      grads = tape.gradient(loss, training_vars)\n",
        "      optimizer.apply_gradients(zip(grads, training_vars))\n",
        "      return loss, accuracy\n",
        "\n",
        "    @tf.function()\n",
        "    def _eval_step(x, y):\n",
        "      if (learning_config.finetune_backbones or\n",
        "          not learning_config.cached_eval):\n",
        "        # Pass the images through multiple backbones.\n",
        "        embeddings = self._embed_batch(x, is_training=False)\n",
        "        # Normalize the data\n",
        "        x = self._process_embeddings(\n",
        "            embeddings, selected_feature_indices,\n",
        "            normalization=learning_config.feature_normalization)\n",
        "      logits = output_head(x)\n",
        "      loss, accuracy = self._compute_loss_and_accuracy(\n",
        "          output_head, logits, y,\n",
        "          global_batch_size=learning_config.eval_batch_size)\n",
        "      return loss, accuracy\n",
        "\n",
        "    for i, (x, y) in enumerate(dist_support_dataset):\n",
        "      if i == learning_config.training_steps:\n",
        "        break\n",
        "      per_replica_results = self.strategy.run(_train_step, args=(x, y))\n",
        "      pr_loss, pr_acc = per_replica_results\n",
        "      support_loss = self.strategy.reduce(\n",
        "          tf.distribute.ReduceOp.SUM, pr_loss, axis=None)\n",
        "      support_accuracy = self.strategy.reduce(\n",
        "          tf.distribute.ReduceOp.SUM, pr_acc, axis=None)\n",
        "      if query_dataset and (i % learning_config.log_freq == 0 or\n",
        "                            i == (learning_config.training_steps - 1)):\n",
        "        logging.info('Evaluating at iteration: %d', i)\n",
        "        all_losses = []\n",
        "        all_accs = []\n",
        "        for query_x, query_y in dist_query_dataset:\n",
        "          per_replica_results = self.strategy.run(_eval_step, args=(\n",
        "              query_x, query_y))\n",
        "          pr_loss, pr_acc = per_replica_results\n",
        "          c_query_loss = self.strategy.reduce(\n",
        "              tf.distribute.ReduceOp.SUM, pr_loss, axis=None)\n",
        "          c_query_accuracy = self.strategy.reduce(\n",
        "              tf.distribute.ReduceOp.SUM, pr_acc, axis=None)\n",
        "          all_losses.append(c_query_loss)\n",
        "          all_accs.append(c_query_accuracy)\n",
        "        # This assumes all batches are same size, so ensure that.\n",
        "        query_loss_iter.append(np.mean(all_losses))\n",
        "        query_accuracy_iter.append(np.mean(all_accs))\n",
        "      support_loss_iter.append(support_loss.numpy())\n",
        "      support_accuracy_iter.append(support_accuracy.numpy())\n",
        "    if learning_config.finetune_backbones:\n",
        "      # Reload the backbones to reset any changes made during finetuning.\n",
        "      with self.strategy.scope():\n",
        "        self.backbones, _, _ = self.load_backbones()\n",
        "    if return_output_head:\n",
        "      return output_head\n",
        "    else:\n",
        "      del output_head.layers[0].kernel\n",
        "      return (support_loss_iter, support_accuracy_iter, query_loss_iter,\n",
        "              query_accuracy_iter)\n",
        "\n",
        "\n",
        "def flatten_and_concat(output_dict, output_keys, pool_size=0, target_size=0,\n",
        "                       cls_token_pool='normal'):\n",
        "  \"\"\"Summarizes a dict of outputs into single feature vector.\"\"\"\n",
        "  # If target_size is given pool_size is ignored.\n",
        "  if cls_token_pool not in ('normal', 'only_cls', 'nopool_cls'):\n",
        "    raise ValueError(\"%s must be one of 'normal', 'only_cls', 'nopool_cls'\"\n",
        "                     % cls_token_pool)\n",
        "  all_features = []\n",
        "  for k in output_keys:\n",
        "    output = output_dict[k]\n",
        "    # TODO Make this more readable by making each branch a function.\n",
        "    if len(output.shape) == 4:\n",
        "      if target_size > 0:\n",
        "        # Overwrite pool size so that final output matches target_size as close\n",
        "        # as possible.\n",
        "        _, width, _, channels = output.shape\n",
        "        if channels >= target_size:\n",
        "          # Global pool.\n",
        "          pool_size = 0\n",
        "        else:\n",
        "          # Assuming square image.\n",
        "          n_patches_per_row = int(math.sqrt(target_size // channels))\n",
        "          pool_size = width // n_patches_per_row\n",
        "      if pool_size > 0:\n",
        "        output = tf.keras.layers.AveragePooling2D(\n",
        "            pool_size=pool_size, strides=pool_size)(output)\n",
        "        all_features.append(tf.keras.layers.Flatten()(output))\n",
        "      else:\n",
        "        # Global pool\n",
        "        all_features.append(tf.reduce_mean(output, axis=[1, 2]))\n",
        "    elif len(output.shape) == 3:\n",
        "      if cls_token_pool == 'only_cls':\n",
        "        output = output[:, 0, :]\n",
        "      else:\n",
        "        if cls_token_pool == 'nopool_cls':\n",
        "          # We will get the cls as it is and pool the rest.\n",
        "          cls_output, output = output[:, 0, :], output[:, 1:, :]\n",
        "        if target_size > 0:\n",
        "          # Overwrite pool size so that final output matches target_size as\n",
        "          # close as possible.\n",
        "          _, n_token, channels = output.shape\n",
        "          if channels >= target_size:\n",
        "            # Global pool.\n",
        "            pool_size = 0\n",
        "          else:\n",
        "            # Assuming square image.\n",
        "            n_groups = target_size / channels\n",
        "            pool_size = int(n_token / n_groups)\n",
        "        if pool_size > 0:\n",
        "          output = tf.keras.layers.AveragePooling1D(\n",
        "              pool_size=pool_size, strides=pool_size)(output)\n",
        "          output = tf.keras.layers.Flatten()(output)\n",
        "        else:\n",
        "          # Global pool\n",
        "          output = tf.reduce_mean(output, axis=[1])\n",
        "        if cls_token_pool == 'nopool_cls':\n",
        "          output = tf.concat([cls_output, output], axis=1)\n",
        "      all_features.append(output)\n",
        "    elif len(output.shape) == 2:\n",
        "      all_features.append(output)\n",
        "    else:\n",
        "      raise ValueError(\n",
        "          f'Output tensor: {k} with shape {output.shape} not 2D or 4D.')\n",
        "  return all_features"
      ],
      "metadata": {
        "id": "sznIfwLn_tdP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Finetune FS"
      ],
      "metadata": {
        "id": "14-EHlZc_6px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import copy\n",
        "\n",
        "from sklearn import ensemble as skens\n",
        "from sklearn import feature_selection as skfs\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "\n",
        "class FinetuneFS(Finetune):\n",
        "  \"\"\"A `tf.keras.Model` implementation of Finetune Feature Selection (FS).\n",
        "  This learner trains a linear classifier on top of the features given.\n",
        "  Additionally it supports having a processing step where a subset of features\n",
        "  are selected.\n",
        "  \"\"\"\n",
        "\n",
        "  def _select_fraction(self, scores, keep_fraction, keep_fraction_offset,\n",
        "                       mean_interpolation_coef=0):\n",
        "    \"\"\"Given a scoring function returns the indices of high scores features.\"\"\"\n",
        "    n_kept = keep_fraction_offset + int(tf.size(scores).numpy() * keep_fraction)\n",
        "    if mean_interpolation_coef > 0:\n",
        "      # We need to interpolate the scores towards it's mean.\n",
        "      scores, _ = self._interpolate_scores_towards_mean(\n",
        "          scores, mean_interpolation_coef)\n",
        "    _, sorted_indices = tf.nn.top_k(scores, k=n_kept)\n",
        "    selected_indices = sorted_indices[keep_fraction_offset:]\n",
        "    return selected_indices\n",
        "\n",
        "  def _interpolate_scores_towards_mean(self, scores, coef):\n",
        "    new_scores = []\n",
        "    mean_scores = []\n",
        "    for c_scores in tf.split(scores, self.embedding_sizes):\n",
        "      c_score_mean = tf.reduce_mean(c_scores)\n",
        "      mean_scores.append(c_score_mean)\n",
        "      c_scores = c_scores * (1 - coef) + c_score_mean * coef\n",
        "      new_scores.append(c_scores)\n",
        "    return tf.concat(new_scores, 0), mean_scores\n",
        "\n",
        "  def _broadcast_indices(self, kept_indices_all):\n",
        "    \"\"\"Splits and removes the offset for indices.\"\"\"\n",
        "    start_index = 0\n",
        "    selected_feature_indices = []\n",
        "    for embedding_size in self.embedding_sizes:\n",
        "      end_index = start_index + embedding_size\n",
        "      kept_indices = tf.boolean_mask(\n",
        "          kept_indices_all,\n",
        "          tf.math.logical_and(\n",
        "              kept_indices_all >= start_index, kept_indices_all < end_index))\n",
        "      # Remove the offset.\n",
        "      kept_indices -= start_index\n",
        "\n",
        "      start_index = end_index\n",
        "      selected_feature_indices.append(kept_indices)\n",
        "    return selected_feature_indices\n",
        "\n",
        "  def _calculate_scores(self, learning_config, dataset):\n",
        "    # Pre-generate the embeddings\n",
        "    config_fs = learning_config.feature_selection\n",
        "    with tf.device('/CPU:0'):\n",
        "      embeddings, labels = self._embed_dataset(dataset)\n",
        "    if config_fs.type == 'random':\n",
        "      concat_embeddings = tf.concat(embeddings, -1)\n",
        "      all_scores = tf.random.normal(concat_embeddings.shape[1:])\n",
        "    elif config_fs.type.startswith('variance'):\n",
        "      concat_embeddings = tf.concat(embeddings, -1)\n",
        "      all_scores = tf.math.reduce_std(concat_embeddings, axis=0)\n",
        "    elif config_fs.type.startswith('sklearn'):\n",
        "      concat_embeddings = tf.concat(embeddings, -1)\n",
        "      f_name = '_'.join(config_fs.type.strip().split('_')[1:])\n",
        "      if f_name == 'trees':\n",
        "        all_scores = skens.ExtraTreesClassifier(n_estimators=50).fit(\n",
        "            concat_embeddings, labels).feature_importances_\n",
        "      else:\n",
        "        score_fn = getattr(skfs, f_name)\n",
        "        all_scores = skfs.SelectPercentile(score_fn).fit(\n",
        "            concat_embeddings, labels).scores_\n",
        "    elif config_fs.type.startswith('connectivity'):\n",
        "      # We don't care about query performance yet.\n",
        "      new_config = copy.deepcopy(learning_config)\n",
        "      # We don't do future selection in this innerloop.\n",
        "      new_config.feature_selection.type = 'none'\n",
        "      if new_config.feature_selection.is_overwrite:\n",
        "        overwrite_dict = new_config.feature_selection.learning_config_overwrite\n",
        "        for k, v in overwrite_dict.items():\n",
        "          setattr(new_config, k, v)\n",
        "      output_head = self._optimize_finetune(new_config, dataset, None,\n",
        "                                            return_output_head=True)\n",
        "      # TODO\n",
        "      weights = output_head.layers[0].kernel\n",
        "\n",
        "      if config_fs.type == 'connectivity_l1':\n",
        "        all_scores = tf.reduce_sum(tf.abs(weights), axis=1)\n",
        "      elif config_fs.type == 'connectivity_l2layer':\n",
        "        if learning_config.group_lrp_is_embedding:\n",
        "          # Here we match the groups used in embedding-based\n",
        "          # group-regularization.\n",
        "          new_scores = []\n",
        "          for group in tf.split(weights, self.embedding_sizes, axis=0):\n",
        "            score = tf.norm(group, axis=1, ord=2)\n",
        "            group_norm = tf.norm(tf.reshape(group, [-1]), ord=2)\n",
        "            new_scores.append(tf.ones_like(score) * group_norm)\n",
        "          all_scores = tf.concat(new_scores, 0)\n",
        "        else:\n",
        "          # This is regular feature wise calculation, followed by averaging.\n",
        "          all_scores = tf.norm(weights, axis=1, ord=2)\n",
        "          # Score of each feature is equal to the layer score.\n",
        "          new_scores = [\n",
        "              tf.ones_like(score) * tf.reduce_mean(score) for score\n",
        "              in tf.split(all_scores, self.embedding_sizes)]\n",
        "          all_scores = tf.concat(new_scores, 0)\n",
        "      elif config_fs.type == 'connectivity_l2':\n",
        "        all_scores = tf.reduce_sum(weights**2, axis=1)\n",
        "      elif config_fs.type == 'connectivity_linf':\n",
        "        all_scores = tf.reduce_max(tf.abs(weights), axis=1)\n",
        "      else:\n",
        "        raise ValueError(f'config_fs.type: {config_fs.type} not valid')\n",
        "      del output_head, weights\n",
        "    else:\n",
        "      raise ValueError(f'{config_fs.type} is not valid')\n",
        "    return all_scores\n",
        "\n",
        "  def _select_features(self, dataset, learning_config):\n",
        "    config_fs = learning_config.feature_selection\n",
        "    if config_fs.type == 'none':\n",
        "      return None, None\n",
        "    if config_fs.average_over_k > 1:\n",
        "      all_scores = []\n",
        "      for _ in range(config_fs.average_over_k):\n",
        "        all_scores.append(self._calculate_scores(learning_config, dataset))\n",
        "      all_scores = tf.reduce_mean(tf.stack(all_scores), 0)\n",
        "    else:\n",
        "      all_scores = self._calculate_scores(learning_config, dataset)\n",
        "    kept_indices_all = self._select_fraction(\n",
        "        all_scores, config_fs.keep_fraction, config_fs.keep_fraction_offset,\n",
        "        mean_interpolation_coef=config_fs.mean_interpolation_coef)\n",
        "    _, mean_scores = self._interpolate_scores_towards_mean(all_scores, 1.)\n",
        "    selected_feature_indices = self._broadcast_indices(kept_indices_all)\n",
        "    return selected_feature_indices, mean_scores\n",
        "\n",
        "  def evaluate(self, learning_config, support_dataset, query_dataset,\n",
        "               fs_dataset=None):\n",
        "    \"\"\"Performs evaluation on an episode.\n",
        "    Args:\n",
        "      learning_config: a `ConfigDict` specifying the learning configuration.\n",
        "      support_dataset: a `tf.data.Dataset` for the support set.\n",
        "      query_dataset: a `tf.data.Dataset` for the query set.\n",
        "      fs_dataset: dataset or None. If given, features are\n",
        "        selected using the datasets given.\n",
        "    Returns:\n",
        "      metrics: dict mapping metric names to metrics.\n",
        "    \"\"\"\n",
        "    # Maybe select features.\n",
        "    if fs_dataset:\n",
        "      selected_feature_indices, mean_scores = self._select_features(\n",
        "          fs_dataset, learning_config)\n",
        "    else:\n",
        "      selected_feature_indices, mean_scores = self._select_features(\n",
        "          support_dataset, learning_config)\n",
        "    metrics = self._optimize_finetune(\n",
        "        learning_config, support_dataset, query_dataset,\n",
        "        selected_feature_indices=selected_feature_indices)\n",
        "    return_dict = self._process_metrics(metrics)\n",
        "\n",
        "    if selected_feature_indices:\n",
        "      for backbone_name, sfi, mean_score in zip(\n",
        "          self.backbone_names, selected_feature_indices, mean_scores):\n",
        "        return_dict[f'fs_count_{backbone_name}/'] = tf.size(sfi).numpy()\n",
        "        return_dict[f'fs_meanscore_{backbone_name}/'] = mean_score.numpy()\n",
        "        return_dict[f'pickle_sfi_{backbone_name}'] = sfi.numpy()\n",
        "    return return_dict"
      ],
      "metadata": {
        "id": "Q5c-c6gM_81P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Config Evals"
      ],
      "metadata": {
        "id": "B2ruPIzZ-3gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ml_collections"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRg7aVTFCeL6",
        "outputId": "4042c847-73c9-40c8-fcb2-5032602880d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ml_collections\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from ml_collections) (1.3.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from ml_collections) (6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from ml_collections) (1.15.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from ml_collections) (0.5.5)\n",
            "Building wheels for collected packages: ml-collections\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94524 sha256=89d626865d33b0b9ffd96879c9e4984bc3b843dcced42f155f963bfad6b2da5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/9f/a9/9e8309035a5bf09ed9086bbca8c9b74cb6413d3eb203e2bc8c\n",
            "Successfully built ml-collections\n",
            "Installing collected packages: ml-collections\n",
            "Successfully installed ml-collections-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from ml_collections import ConfigDict\n",
        "\n",
        "\n",
        "def get_config_fine_tune(config_string):\n",
        "  train_batch_size = 128\n",
        "  eval_batch_size = 50\n",
        "  config = ConfigDict({\n",
        "      'dataset':\n",
        "          'data.caltech101',\n",
        "      'eval_mode':\n",
        "          'valid',\n",
        "      'is_vtab_5fold_valid':\n",
        "          True,\n",
        "      'seed':\n",
        "          8,\n",
        "      'max_num_gpus':\n",
        "          1,\n",
        "      'learning':\n",
        "          ConfigDict({\n",
        "              'optimizer': 'adam',  #  adadelta, adadelta_adaptive, sgd\n",
        "              'learning_rate': 0.1,\n",
        "              'grad_clip_value': -1.,  # Applied if positive.\n",
        "              'l1_regularizer': 0.,\n",
        "              'l2_regularizer': 0.,\n",
        "              'group_lrp_regularizer_coef': 0.,\n",
        "              'group_lrp_regularizer_r': 2.,\n",
        "              'group_lrp_regularizer_p': 1.,\n",
        "              'group_lrp_is_embedding': False,\n",
        "              'training_steps': 500,\n",
        "              'data_fraction': 1.,\n",
        "              'cached_eval': True,\n",
        "              'use_cosine_decay': True,\n",
        "              'train_batch_size': train_batch_size,\n",
        "              'eval_batch_size': eval_batch_size,\n",
        "              'finetune_backbones': False,\n",
        "              'finetune_lr_multiplier': 1.,\n",
        "              'finetune_steps_multiplier': 1.,\n",
        "              # ('', 'unit_vector', 'per_feature')\n",
        "              'feature_normalization': 'unit_vector',\n",
        "              # nohidden, random_100, random_1000, trainable_100, trainable_1000\n",
        "              'output_head_type': 'nohidden',\n",
        "              'output_head_zeroinit': False,\n",
        "              'log_freq': 50,\n",
        "          }),\n",
        "      'model_name':\n",
        "          'Finetune'\n",
        "  })\n",
        "\n",
        "  config.backbone = get_backbone_config(config_string)\n",
        "  print(f'Config backbone: {config.backbone}')\n",
        "  return config\n",
        "\n",
        "\n",
        "def get_backbone_config(config_string):\n",
        "  \"\"\"Gets backbone configuration according to the key given.\"\"\"\n",
        "  # Example patterns:\n",
        "  # imagenetr50, imagenetr50_2x\n",
        "  pattern = r'^([A-Za-z0-9]+)?_?(\\d+)?x?'\n",
        "  searched = re.search(pattern, config_string)\n",
        "  if not searched:\n",
        "    raise ValueError(f'Unrecognized config_string: {config_string}')\n",
        "  added_backbone, n_repeat = searched.groups()\n",
        "  print(f'Split config: {added_backbone}, {n_repeat}')\n",
        "  processed_names = []\n",
        "  processed_handles = []\n",
        "  processed_signatures = []\n",
        "  processed_output_keys = []\n",
        "  input_sizes = tuple()\n",
        "\n",
        "  if added_backbone in SINGLE_MODELS:\n",
        "    n_repeat = int(n_repeat) if n_repeat else 1\n",
        "    processed_names += [added_backbone] * n_repeat\n",
        "    handle, size = SINGLE_MODELS[added_backbone]\n",
        "    if isinstance(handle, list):\n",
        "      processed_handles = handle * n_repeat\n",
        "      processed_handles = processed_handles[:n_repeat]\n",
        "    else:\n",
        "      processed_handles += [handle] * n_repeat\n",
        "\n",
        "    if 'vit' in added_backbone:\n",
        "      processed_signatures += ['serving_default'] * n_repeat\n",
        "      processed_output_keys += ['pre_logits'] * n_repeat\n",
        "    else:\n",
        "      processed_signatures += ['representation'] * n_repeat\n",
        "      processed_output_keys += ['pre_logits'] * n_repeat\n",
        "    input_sizes += (size,) * n_repeat\n",
        "  else:\n",
        "    raise ValueError(f'added_backbone:{added_backbone} is not recognized')\n",
        "\n",
        "  return ConfigDict({\n",
        "      'names': processed_names,\n",
        "      'handles': processed_handles,\n",
        "      'signatures': processed_signatures,\n",
        "      'output_keys': processed_output_keys,\n",
        "      'input_sizes': input_sizes,\n",
        "      'include_input': False,\n",
        "      'additional_features': '',\n",
        "      'additional_features_pool_size': 0,\n",
        "      'cls_token_pool': 'normal',\n",
        "      # If target size is provided, pool size is ignored.\n",
        "      'additional_features_target_size': 0,\n",
        "      'additional_features_multi_target_sizes': '',\n",
        "  })\n",
        "\n",
        "\n",
        "SINGLE_MODELS = {\n",
        "    'imagenetr50': ('checkpoints/imagenetr50/', 240),\n",
        "    'imagenetvitB16': ('checkpoints/imagenetvitB16/', 224)\n",
        "}"
      ],
      "metadata": {
        "id": "_LnAEaHR-wOS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ml_collections import ConfigDict\n",
        "\n",
        "\n",
        "def get_config_fine_tune_fs(config_string):\n",
        "  config = get_config_fine_tune(config_string)\n",
        "  config['model_name'] = 'FinetuneFS'\n",
        "  new_learning_config = ConfigDict({\n",
        "      'feature_selection':\n",
        "          ConfigDict({\n",
        "              # Following types exist: 'connectivity_mask',\n",
        "              # 'connectivity_l1', 'random', 'none', 'variance' and\n",
        "              # 'sklearn_x' where x in\n",
        "              # [chi2, f_classif, mutual_info_classif, trees]\n",
        "              'type': 'none',\n",
        "              'fs_dataset': '',\n",
        "              'is_overwrite': False,\n",
        "              'average_over_k': 1,\n",
        "              'keep_fraction': 0.1,\n",
        "              'keep_fraction_offset': 0,\n",
        "              'mean_interpolation_coef': 0.,\n",
        "              'learning_config_overwrite':\n",
        "                  ConfigDict({\n",
        "                      'group_lrp_regularizer_coef': 1e-4,\n",
        "                      'finetune_backbones': False,\n",
        "                  })\n",
        "          }),\n",
        "  })\n",
        "  config['learning'].update(new_learning_config)\n",
        "  print(f'Config backbone: {config.backbone}')\n",
        "  return "
      ],
      "metadata": {
        "id": "HoDaSkQD-jwq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_config_fine_tune_h2t(config_string):\n",
        "  config = get_config_fine_tune_fs(config_string)\n",
        "  if 'imagenetr50' in config_string:\n",
        "    all_blocks = set({'after_root', 'logits', 'pre_logits_pre_pooling'})\n",
        "    for i, j in enumerate([3, 4, 6, 3]):\n",
        "      for k in range(j):\n",
        "        for l in range(3):\n",
        "          all_blocks.add(f'block{i+1}_unit{k+1}_layer{l}')\n",
        "  elif 'imagenetvitB16' in config_string:\n",
        "    all_blocks = set({'cls_embedded', 'encoded_sequence',\n",
        "                      'position_embedded_input', 'root_output_with_cls'})\n",
        "    for i in range(12):\n",
        "      all_blocks.add(f'encoder_{i}_attn')\n",
        "      all_blocks.add(f'encoder_{i}_mlp_1')\n",
        "      all_blocks.add(f'encoder_{i}_mlp_2')\n",
        "      all_blocks.add(f'encoder_{i}_pre_attn')\n",
        "  else:\n",
        "    raise ValueError(f'This config is not supported for {config_string}')\n",
        "  config.backbone.additional_features = ','.join(all_blocks)\n",
        "  config.learning.feature_selection.type = 'connectivity_l2'\n",
        "  config.learning.feature_selection.is_overwrite = True\n",
        "  print(f'Config backbone: {config.backbone}')\n",
        "  return config"
      ],
      "metadata": {
        "id": "C6soDwoh-uPH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Input pipeline"
      ],
      "metadata": {
        "id": "JwOr4AvUBqNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/google-research/task_adaptation.git#egg=task_adaptation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2JdM-juCo4B",
        "outputId": "a2bbcc77-3b1b-4ece-8604-945896c18586"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting task_adaptation\n",
            "  Cloning https://github.com/google-research/task_adaptation.git to /tmp/pip-install-s2onrpxg/task-adaptation_ad64b6b10dac44fcb5e58dbf8b93ab2d\n",
            "  Running command git clone -q https://github.com/google-research/task_adaptation.git /tmp/pip-install-s2onrpxg/task-adaptation_ad64b6b10dac44fcb5e58dbf8b93ab2d\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from task_adaptation) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from task_adaptation) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from task_adaptation) (1.15.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from task_adaptation) (2.9.2)\n",
            "Collecting tfds-nightly\n",
            "  Downloading tfds_nightly-4.7.0.dev202212080045-py3-none-any.whl (5.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.0 MB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub in /usr/local/lib/python3.8/dist-packages (from task_adaptation) (0.12.0)\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (4.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (2.9.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (21.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (2.9.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (1.12)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (14.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (2.1.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (2.9.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (1.51.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (3.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (3.19.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (0.28.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->task_adaptation) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->task_adaptation) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->task_adaptation) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow->task_adaptation) (3.0.9)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons->task_adaptation) (2.7.1)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tfds-nightly->task_adaptation) (0.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from tfds-nightly->task_adaptation) (0.1.7)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tfds-nightly->task_adaptation) (0.3.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tfds-nightly->task_adaptation) (1.11.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tfds-nightly->task_adaptation) (0.10.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tfds-nightly->task_adaptation) (2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tfds-nightly->task_adaptation) (4.64.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tfds-nightly->task_adaptation) (5.10.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tfds-nightly->task_adaptation) (1.57.0)\n",
            "Building wheels for collected packages: task-adaptation\n",
            "  Building wheel for task-adaptation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for task-adaptation: filename=task_adaptation-0.1-py3-none-any.whl size=89354 sha256=10338438e9ed6828b3ade69f8a43c39508f8ba27eabb03fe6c45a583da2d594b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1c36yd5h/wheels/23/11/5e/9840def20623a9efdca9c87b23b905878023a417500a119932\n",
            "Successfully built task-adaptation\n",
            "Installing collected packages: tfds-nightly, tensorflow-addons, mock, task-adaptation\n",
            "Successfully installed mock-4.0.3 task-adaptation-0.1 tensorflow-addons-0.18.0 tfds-nightly-4.7.0.dev202212080045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import functools\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "from task_adaptation import data_loader\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "\n",
        "def _filter_to_k_shot(dataset, num_classes, k):\n",
        "  \"\"\"Filters k-shot subset from a dataset.\"\"\"\n",
        "  # !!! IMPORTANT: the dataset should *not* be shuffled. !!!\n",
        "  # Make sure that `shuffle_buffer_size=1` in the call to\n",
        "  # `dloader.get_tf_data`.\n",
        "\n",
        "  # Indices of included examples in the k-shot balanced dataset.\n",
        "  keep_example = []\n",
        "  # Keep track of the number of examples per class included in\n",
        "  # `keep_example`.\n",
        "  class_counts = np.zeros([num_classes], dtype=np.int32)\n",
        "  for _, label in dataset.as_numpy_iterator():\n",
        "    # If there are less than `k` examples of class `label` in `example_indices`,\n",
        "    # keep this example and update the class counts.\n",
        "    keep = class_counts[label] < k\n",
        "    keep_example.append(keep)\n",
        "    if keep:\n",
        "      class_counts[label] += 1\n",
        "    # When there are `k` examples for each class included in `keep_example`,\n",
        "    # stop searching.\n",
        "    if (class_counts == k).all():\n",
        "      break\n",
        "\n",
        "  dataset = tf.data.Dataset.zip((\n",
        "      tf.data.Dataset.from_tensor_slices(keep_example),\n",
        "      dataset\n",
        "  )).filter(lambda keep, _: keep).map(lambda _, example: example).cache()\n",
        "\n",
        "  return dataset\n",
        "\n",
        "\n",
        "def create_vtab_dataset_balanced(dataset, image_size, batch_size,\n",
        "                                 data_fraction):\n",
        "  \"\"\"Creates a VTAB input_fn to be used by `tf.Estimator`.\n",
        "  Deterministic balanced sampling from vtab datasets.\n",
        "  Args:\n",
        "    dataset: str, VTAB task to evaluate on.\n",
        "    image_size: int\n",
        "    batch_size: int\n",
        "    data_fraction: float, used to calculate n_shots\n",
        "  Returns:\n",
        "    input_fn, input function to be passed to `tf.Estimator`.\n",
        "  \"\"\"\n",
        "  dloader = data_loader.get_dataset_instance(\n",
        "      {'dataset': dataset, 'data_dir': None})\n",
        "  num_classes = dloader.get_num_classes()\n",
        "  n_shots = max(int(1000 * data_fraction / num_classes), 1)\n",
        "  logging.info('n_shots: %d', n_shots)\n",
        "  def _dict_to_tuple(batch):\n",
        "    return batch['image'], batch['label']\n",
        "  dataset = dloader.get_tf_data(\n",
        "      split_name='trainval',\n",
        "      batch_size=batch_size,\n",
        "      preprocess_fn=functools.partial(\n",
        "          data_loader.preprocess_fn,\n",
        "          input_range=(-1.0, 1.0),\n",
        "          size=image_size),\n",
        "      epochs=0,\n",
        "      drop_remainder=False,\n",
        "      for_eval=False,\n",
        "      shuffle_buffer_size=1,\n",
        "      prefetch=1,\n",
        "      train_examples=None,\n",
        "  ).unbatch().map(_dict_to_tuple)\n",
        "  filtered_dataset = _filter_to_k_shot(dataset, num_classes, n_shots)\n",
        "  return filtered_dataset.shuffle(1000).batch(batch_size)\n",
        "\n",
        "\n",
        "def create_vtab_dataset(dataset, image_size, batch_size, mode,\n",
        "                        eval_mode='test', valid_fold_id=4):\n",
        "  \"\"\"Creates a VTAB input_fn to be used by `tf.Estimator`.\n",
        "  Note: There is one episode/VTAB dataset.\n",
        "  Args:\n",
        "    dataset: str, VTAB task to evaluate on.\n",
        "    image_size: int\n",
        "    batch_size: int\n",
        "    mode: str in {'train', 'eval'}, whether to build the input function for\n",
        "      training or evaluation.\n",
        "    eval_mode: str in {'valid', 'test'}, whether to build the input functions\n",
        "      for validation or test runs.\n",
        "    valid_fold_id: int, 0 <= valid_fold_id < 5, valid_fold_id=4 corresponds to\n",
        "      the default value in VTAB.\n",
        "  Returns:\n",
        "    input_fn, input function to be passed to `tf.Estimator`.\n",
        "  \"\"\"\n",
        "  assert 0 <= valid_fold_id < 5\n",
        "  dloader = data_loader.get_dataset_instance(\n",
        "      {'dataset': dataset, 'data_dir': None})\n",
        "  if mode not in ('train', 'eval'):\n",
        "    raise ValueError(\"mode should be 'train' or 'eval'\")\n",
        "  is_training = mode == 'train'\n",
        "\n",
        "  def _dict_to_tuple(batch):\n",
        "    return batch['image'], batch['label']\n",
        "  if eval_mode == 'test':\n",
        "    split_name = 'train800val200' if is_training else 'test'\n",
        "  elif eval_mode == 'valid':\n",
        "    val_start, val_end = valid_fold_id * 200, (valid_fold_id + 1) * 200\n",
        "    if is_training:\n",
        "      split_name = f'train[:{val_start}]+train[{val_end}:1000]'\n",
        "    else:\n",
        "      split_name = f'train[{val_start}:{val_end}]'\n",
        "    logging.info('Using split_name: %s', split_name)\n",
        "\n",
        "    if split_name not in dloader._tfds_splits:\n",
        "      dloader._tfds_splits[split_name] = split_name\n",
        "      dloader._num_samples_splits[split_name] = 800 if is_training else 200\n",
        "  else:\n",
        "    raise ValueError(f'eval_mode: {eval_mode} invalid')\n",
        "\n",
        "  return dloader.get_tf_data(\n",
        "      split_name=split_name,\n",
        "      batch_size=batch_size,\n",
        "      preprocess_fn=functools.partial(\n",
        "          data_loader.preprocess_fn,\n",
        "          input_range=(-1.0, 1.0),\n",
        "          size=image_size),\n",
        "      epochs=0,\n",
        "      drop_remainder=False,\n",
        "      for_eval=not is_training,\n",
        "      # Our training data has at most 1000 samples, therefore a shuffle buffer\n",
        "      # size of 1000 is sufficient.\n",
        "      shuffle_buffer_size=1000,\n",
        "      prefetch=1,\n",
        "      train_examples=None,\n",
        "  ).map(_dict_to_tuple)"
      ],
      "metadata": {
        "id": "JxiV-oQSBsNY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate"
      ],
      "metadata": {
        "id": "D5m0mZpJBXa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "from absl import app\n",
        "from absl import flags\n",
        "from absl import logging\n",
        "from ml_collections import config_flags\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "flags = tf.compat.v1.flags\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "def main(unused_argv):\n",
        "  config = FLAGS.config\n",
        "  dataset_name = config.dataset\n",
        "\n",
        "  image_size = max(config.backbone.input_sizes)\n",
        "  # The entire dataset is the episode for VTAB.\n",
        "  # We calculate average accuracy if is validation.\n",
        "  # If the crossvalidation is not enabled, then we perform only 5th fold,\n",
        "  # which is the default validation set.\n",
        "  if config.is_vtab_5fold_valid and config.eval_mode == 'valid':\n",
        "    start_idx = 0\n",
        "  else:\n",
        "    start_idx = 4\n",
        "  end_idx = 5\n",
        "\n",
        "  if config.model_name == 'Finetune':\n",
        "    model = Finetune(config)\n",
        "  elif config.model_name == 'FinetuneFS':\n",
        "    model = FinetuneFS(config)\n",
        "  else:\n",
        "    print(f'config.model_name: {config.model_name} not valid.')\n",
        "\n",
        "  episode_metrics = []\n",
        "  print('Writing training logs to %s', FLAGS.output_dir)\n",
        "  writer = tf.summary.create_file_writer(FLAGS.output_dir)\n",
        "  writer.set_as_default()\n",
        "  start_time = time.time()\n",
        "  for episode_idx in range(start_idx, end_idx):\n",
        "    t0 = time.perf_counter()\n",
        "    input_fn = functools.partial(\n",
        "        create_vtab_dataset, config.dataset,\n",
        "        image_size=image_size, eval_mode=config.eval_mode,\n",
        "        valid_fold_id=episode_idx)\n",
        "    if config.learning.data_fraction != 1:\n",
        "      print('Fractional data: %f', config.learning.data_fraction)\n",
        "      support_dataset = create_vtab_dataset_balanced(\n",
        "          config.dataset, image_size=image_size,\n",
        "          batch_size=config.learning.train_batch_size,\n",
        "          data_fraction=config.learning.data_fraction)\n",
        "    else:\n",
        "      support_dataset = input_fn(mode='train',\n",
        "                                 batch_size=config.learning.train_batch_size)\n",
        "    query_dataset = input_fn(mode='eval',\n",
        "                             batch_size=config.learning.eval_batch_size)\n",
        "    if (hasattr(config.learning, 'feature_selection') and\n",
        "        config.learning.feature_selection.fs_dataset):\n",
        "      input_fn = functools.partial(\n",
        "          create_vtab_dataset,\n",
        "          config.learning.feature_selection.fs_dataset,\n",
        "          image_size=image_size, eval_mode=config.eval_mode,\n",
        "          valid_fold_id=episode_idx)\n",
        "      fs_dataset = input_fn(\n",
        "          mode='train', batch_size=config.learning.train_batch_size)\n",
        "    else:\n",
        "      fs_dataset = None\n",
        "    metrics = model.evaluate(config.learning,\n",
        "                             support_dataset,\n",
        "                             query_dataset,\n",
        "                             fs_dataset=fs_dataset)\n",
        "    episode_metrics.append(metrics)\n",
        "    print('Episode time %f:', time.perf_counter() - t0)\n",
        "    print('Episode: %i', episode_idx)\n",
        "    print('Final support loss: %f', metrics['support_loss'])\n",
        "    print('Final support accuracy: %4.2f%%',\n",
        "                 100 * metrics['support_accuracy'])\n",
        "    print('Final query loss: %f', metrics['query_loss'])\n",
        "    print('Final query accuracy: %4.2f%%',\n",
        "                 100 * metrics['query_accuracy'])\n",
        "    tf.summary.scalar(\n",
        "        'query_accuracy', metrics['query_accuracy'], step=episode_idx)\n",
        "\n",
        "    pickle_metrics = {}\n",
        "    for name, value in metrics.items():\n",
        "      if np.isscalar(value):\n",
        "        tf.summary.scalar(f'metrics/{name}', value, step=episode_idx)\n",
        "      elif name.startswith('pickle'):\n",
        "        pickle_metrics[name] = value\n",
        "      else:\n",
        "        print(f'metric: {name} not valid')\n",
        "\n",
        "    writer.flush()\n",
        "    print('Total iteration time %f:', time.perf_counter() - t0)\n",
        "  print('Elapsed time %f:', time.time() - start_time)\n",
        "  all_q_accs = [m['query_accuracy'] for m in episode_metrics]\n",
        "  acc_mean, acc_std = np.mean(all_q_accs), np.std(all_q_accs)\n",
        "  print('Query Accucary Mean: %.2f', acc_mean)\n",
        "  print('Query Accucary Std: %.2f', acc_std)\n",
        "\n"
      ],
      "metadata": {
        "id": "HTtq7mNKBYwf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.enable_v2_behavior()\n",
        "\n",
        "class learning_config_overwrite:\n",
        "    group_lrp_regularizer_coef=0.00001;\n",
        "\n",
        "class feature_selection:\n",
        "    keep_fraction=0.2;\n",
        "    learning_config_overwrite = learning_config_overwrite();\n",
        "\n",
        "class learning:\n",
        "    cached_eval=False;\n",
        "    feature_selection = feature_selection();\n",
        "    feature_selection.learning_config_overwrite.group_lrp_regularizer_coef=0.00001;\n",
        "    learning_rate=0.01;\n",
        "    training_steps=500;\n",
        "    log_freq=1000;\n",
        "\n",
        "class backbone:\n",
        "    additional_features_target_size=512;\n",
        "\n",
        "class config:\n",
        "    dataset = '';\n",
        "    eval_model = '';\n",
        "    learning = learning();\n",
        "    backbone = backbone();\n",
        "    \n",
        "config.dataset='data.dsprites(predicted_attribute=\"label_orientation\",num_classes=16)'\n",
        "config.eval_mode='test'\n",
        "config.learning.cached_eval=False\n",
        "config.backbone.additional_features_target_size=512\n",
        "config.learning.feature_selection.keep_fraction=0.2\n",
        "config.learning.feature_selection.learning_config_overwrite.group_lrp_regularizer_coef=0.00001\n",
        "config.learning.learning_rate=0.01\n",
        "config.learning.training_steps=500\n",
        "config.learning.log_freq=1000\n"
      ],
      "metadata": {
        "id": "uCi07oLGXpcQ"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}